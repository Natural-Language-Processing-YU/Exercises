{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk1degdaoXx6cGqhT5fy3y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Natural-Language-Processing-YU/Exercises/blob/main/Exercise_Using_NLTK_Library.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise: Text Preprocessing with NLTK\n",
        "\n",
        "Description:\n",
        "In this exercise, students will use NLTK to perform basic text preprocessing tasks on a given dataset. They will apply various NLTK functionalities to clean and normalize the words, preparing them for further analysis or modeling.\n",
        "\n"
      ],
      "metadata": {
        "id": "EQP9G5-Vb7j5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions:\n",
        "\n",
        "Introduce the concept of text preprocessing to the students, explaining its importance in natural language processing tasks. Discuss common preprocessing steps, such as tokenization, removing punctuation, converting to lowercase, and removing stopwords.\n",
        "\n",
        "Provide the students with a dataset containing a sample text document. It could be a paragraph or a collection of sentences.\n",
        "\n",
        "Instruct students to write a Python script that uses NLTK to preprocess the words in the given text document.\n",
        "\n",
        "Students should apply the following preprocessing steps using NLTK:\n",
        "\n",
        "* Tokenization: Split the text into individual words or tokens.\n",
        "* Removing punctuation: Remove any punctuation marks from the words.\n",
        "* Converting to lowercase: Convert all words to lowercase for consistency.\n",
        "* Removing stopwords: Remove common stopwords (e.g., \"the,\" \"is,\" \"and\") that do not contribute much to the meaning of the text.\n",
        "\n",
        "\n",
        "Students should  experiment with additional preprocessing steps or NLTK functionalities based on their understanding and familiarity with the toolkit"
      ],
      "metadata": {
        "id": "vyvaXqJ2cEDl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQf_4s79bxLz",
        "outputId": "977e281b-6871-4985-b416-f0cdeac1094d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sample', 'sentence', 'text', 'preprocessing']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "#import libraries, corpora, and stopword library\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example using nltk\n",
        "def preprocess_text(text):\n",
        "  tokens = word_tokenize(text)\n",
        "\n",
        "    # Removing punctuation and converting to lowercase\n",
        "  tokens = [token.lower() for token in tokens if token not in punctuation]\n",
        "\n",
        "    # Removing stopwords\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "  return tokens\n",
        "\n",
        "# Test the preprocessing function with a sample text\n",
        "text = \"This is a sample sentence for text preprocessing.\"\n",
        "preprocessed_tokens = preprocess_text(text)\n",
        "print(preprocessed_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9EEwBhsc8Uk",
        "outputId": "c66037d8-e581-47ce-8fca-c939daff2479"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sample', 'sentence', 'text', 'preprocessing']\n"
          ]
        }
      ]
    }
  ]
}